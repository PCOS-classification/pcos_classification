# -*- coding: utf-8 -*-
"""notebookaa5e115.ipyvggnb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n6iDgvY1wlKnVkB5DGLk4t3tk2AbiJoI
"""

import os
import pandas as pd
import numpy as np
import imgaug.augmenters as iaa
import cv2
import random

def load_image_paths_from_folder(folder_path):
    image_paths = []
    for filename in os.listdir(folder_path):
        img_path = os.path.join(folder_path, filename)
        image_paths.append(img_path)
    return image_paths

# Define the two folders containing the images
folder_path_classA = r"/content/drive/MyDrive/datset/datset/non_pcos"
folder_path_classB = r"/content/drive/MyDrive/datset/datset/pcos"

# Load image paths for classA
image_paths_classA = load_image_paths_from_folder(folder_path_classA)

# Load image paths for classB
image_paths_classB = load_image_paths_from_folder(folder_path_classB)

# Balance the dataset by augmenting images in classB
num_images_to_add = len(image_paths_classA) - len(image_paths_classB)
augmented_image_paths_classB = []
augmentation_factor = int(num_images_to_add / len(image_paths_classB)) + 1
augmentor = iaa.Sequential([
    iaa.Fliplr(0.5),  # horizontally flip 50% of the images
    iaa.Affine(rotate=(-10, 10)),  # rotate images by -10 to 10 degrees
    iaa.GaussianBlur(sigma=(0, 1.0)),  # blur images with a sigma of 0 to 1.0
])

for _ in range(augmentation_factor):
    for image_path in image_paths_classB:
        augmented_image_paths_classB.append(image_path)

# Randomly shuffle augmented image paths and select a subset to match the number of images in class A
random.shuffle(augmented_image_paths_classB)
augmented_image_paths_classB = augmented_image_paths_classB[:num_images_to_add]

# Combine original and augmented image paths for classB
image_paths_classB += list(augmented_image_paths_classB)

# Ensure that the lengths of image paths are the same
min_length = min(len(image_paths_classA), len(image_paths_classB))
image_paths_classA = image_paths_classA[:min_length]
image_paths_classB = image_paths_classB[:min_length]

# Create labels
labels_classA = ["non_pcos"] * len(image_paths_classA)
labels_classB = ["pcos"] * len(image_paths_classB)

# Combine the data from both classes into a single DataFrame
data = {
    "image_path": image_paths_classA + image_paths_classB,
    "label": labels_classA + labels_classB
}

df = pd.DataFrame(data)

# Shuffle the DataFrame (optional)
df = df.sample(frac=1).reset_index(drop=True)

# Now, the DataFrame 'df' contains the balanced image data paths and corresponding labels from both classes.
# You can use this DataFrame for further processing or training your model.

df

from google.colab import drive
drive.mount('/content/drive')

from sklearn.preprocessing import LabelEncoder
# Create an instance of LabelEncoder
label_encoder = LabelEncoder()

# Fit and transform the labels in the DataFrame
df["encoded_label"] = label_encoder.fit_transform(df["label"])

print(df)

import pandas as pd
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split

def load_and_preprocess_image(image_path, image_width, image_height):
    image = Image.open(image_path)
    image = image.resize((image_width, image_height))
    image_array = np.array(image) / 255.0
    return image_array

from tensorflow.keras.utils import to_categorical
X = np.array([load_and_preprocess_image(str(path), 224,224) for path in df['image_path']])
y = to_categorical(df['encoded_label'])

# # Split the dataset into training and testing sets
# image_width = 224
# image_height = 224
# X = np.array([load_and_preprocess_image(str(path), image_width, image_height) for path in df['image_path']])
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense, Flatten
# from tensorflow.keras.utils import to_categorical
# from tensorflow.keras.callbacks import ModelCheckpoint
# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Define the model
# model = Sequential([
#     Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),
#     MaxPooling2D((2, 2)),
#     Conv2D(64, (3, 3), activation='relu'),
#     MaxPooling2D((2, 2)),
#     Conv2D(128, (3, 3), activation='relu'),
#     MaxPooling2D((2, 2)),
#     Conv2D(128, (3, 3), activation='relu'),
#     MaxPooling2D((2, 2)),
#     Flatten(),
#     Dense(512, activation='relu'),
#     Dense(2, activation='softmax')  # Output layer with 2 units for binary classification
# ])

# # Compile the model
# model.compile(optimizer='adam',
#               loss='categorical_crossentropy',
#               metrics=['accuracy'])

# # Define a checkpoint callback to save the best model
# checkpoint_path = "model_checkpoint.h5"
# checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,
#                                       save_best_only=True,
#                                       verbose=1)

# # Train the model
# model.fit(X_train, y_train,
#           epochs=50,
#           batch_size=32,
#           validation_split=0.2,
#           callbacks=[checkpoint_callback])

# # Load the best model from the checkpoint
# model.load_weights(checkpoint_path)

# # Evaluate the model on the test set
# test_loss, test_accuracy = model.evaluate(X_test, y_test)
# print("Test Loss:", test_loss)
# print("Test Accuracy:", test_accuracy)

# # Save the model as HDF5 file
# model.save("dense_model.h5")

from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import ModelCheckpoint
# Split the dataset into training, validation, and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(2, activation='softmax')  # Output layer with 2 units for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Define a checkpoint callback to save the best model
checkpoint_path = "model_checkpoint.h5"
checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,
                                      save_best_only=True,
                                      verbose=1)

# Train the model with validation data
history = model.fit(X_train, y_train,
                    epochs=30,
                    batch_size=32,
                    validation_data=(X_val, y_val),
                    callbacks=[checkpoint_callback])

# Load the best model from the checkpoint
model.load_weights(checkpoint_path)

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

# Save the model as HDF5 file
model.save("dense_model.h5")

# Plot training and validation accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

from tensorflow.keras.models import load_model

# Load the model from the H5 file
loaded_model = load_model('dense_model.h5')

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.layers import MultiHeadAttention
from tensorflow.keras.optimizers import Adam
# Assuming you have a pre-trained feature extractor model (e.g., a CNN)
pretrained_feature_extractor = loaded_model.layers[-3]

# Get the output shape of the feature extraction layer
feature_shape = pretrained_feature_extractor.output_shape[1:]

base_model = models.Model(inputs=loaded_model.input, outputs=loaded_model.layers[-3].output)
# Print the shape for debugging
print("Feature Shape:", feature_shape)

# Define your transformer model
def transformer_model(input_shape, num_transformer_layers, output_dim):
    inputs = tf.keras.Input(shape=input_shape)

    # Add a "sequence_length" dimension to the input
    sequence = layers.Reshape((1, input_shape[0]))(inputs)

    # Transformer layers using MultiHeadAttention
    sequence = MultiHeadAttention(num_heads=5, key_dim=64)(sequence, sequence)
    sequence = layers.LayerNormalization(epsilon=1e-6)(sequence)
    sequence = layers.Dropout(0.1)(sequence)

    # Reshape the sequence to maintain 3D structure
    sequence = layers.Reshape((-1, feature_shape[0]))(sequence)

    # Output layer for your specific task
    outputs = layers.Dense(output_dim, activation='softmax')(sequence)

    model = models.Model(inputs=inputs, outputs=outputs)
    return model

# Define your task-specific output dimension (e.g., number of classes)
output_dim = 2
num_tlayers = 2

# Create the transformer model
transformer = transformer_model(input_shape=feature_shape, num_transformer_layers=num_tlayers, output_dim=output_dim)

# Print the summary of the model for debugging
transformer.summary()

# Combine the pre-trained feature extractor with the transformer
combined_model = models.Sequential([
    base_model,
    transformer,
    layers.Flatten()  # Add Flatten layer to reshape the output
])

# Compile the model (adjust loss and metrics based on your task)
combined_model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

# Print the summary of the combined model
#combined_model.summary()

# Train the combined model on your task-specific data
combined_model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)



import tensorflow as tf

# Check if TensorFlow is using GPU
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# Print GPU details
print("GPU Details:")
for gpu in tf.config.experimental.list_physical_devices('GPU'):
    print(gpu)

combined_model.save('VIT.plt')

import os
import pandas as pd
import numpy as np

def load_images_from_folder(folder_path, label):
    images = []
    labels = []
    for filename in os.listdir(folder_path):
        img = os.path.join(folder_path, filename)
        # if img is not None:
        #     img = cv2.resize(img, (227, 227))  # Resize the images to match the input shape of AlexNet
        #     img=np.array(img)
        images.append(img)
        labels.append(label)
    return images, labels

# Define the two folders containing the images and their corresponding labels
folder_path_classA = r"/content/drive/MyDrive/datset/datset/non_pcos"
folder_path_classB = r"/content/drive/MyDrive/datset/datset/pcos"

# Load images and labels for classA
images_classA, labels_classA = load_images_from_folder(folder_path_classA, label="non_pcos")

# Load images and labels for classB
images_classB, labels_classB = load_images_from_folder(folder_path_classB, label="pcos")


# Combine the data from both classes into a single DataFrame
data = {
    "image": images_classA + images_classB,
    "label": labels_classA + labels_classB
}

dft= pd.DataFrame(data)

# Shuffle the DataFrame (optional)
dft = df.sample(frac=1).reset_index(drop=True)

# Now, the DataFrame 'df' contains the image data and corresponding labels from both folders.
# You can use this DataFrame for further processing or training your model.

from sklearn.preprocessing import LabelEncoder
# Create an instance of LabelEncoder
label_encoder = LabelEncoder()

# Fit and transform the labels in the DataFrame
dft["encoded_label"] = label_encoder.fit_transform(dft["label"])

print(dft)

import pandas as pd
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split

def load_and_preprocess_image(image_path, image_width, image_height):
    image = Image.open(image_path)
    image = image.resize((image_width, image_height))
    image_array = np.array(image) / 255.0
    return image_array

from tensorflow.keras.utils import to_categorical
Xt = np.array([load_and_preprocess_image(str(path), 224,224) for path in dft['image_path']])
yt = to_categorical(dft['encoded_label'])

import tensorflow as tf

# Load the model from the H5 file
loaded_model = load_model('VIT.plt')

# Get the output of the last convolutional layer
last_conv_layer_output = loaded_model.layers[-1].output  # Assuming the last convolutional layer is the fourth from the end

# Define a new model that outputs the features from the last convolutional layer
feature_extraction_model = tf.keras.Model(inputs=loaded_model.input, outputs=last_conv_layer_output)

# Use this model to extract features from your data
features = feature_extraction_model.predict(Xt)

# 'features' now contains the extracted features from the last convolutional layer
# You can use these features for further analysis or visualization

print(features)

import tensorflow as tf

# Load the model from the H5 file
loaded_model = load_model('VIT.plt')

# Assuming Xt contains the input images with shape (None, 224, 224, 3)
# where None is the batch size and 224x224x3 is the image dimensions and channels
# Ensure that Xt has the correct shape
print("Input data shape:", Xt.shape)

# Use this model to extract features from your data
features = loaded_model.predict(Xt)

# 'features' now contains the extracted features
# You can use these features for further analysis or visualization

from tensorflow.keras.models import load_model

# Load the model from the H5 file
model = load_model('VIT.plt')

# Now, you can use the loaded_model to make predictions on new data
# For example:
import numpy as np

# Assuming you have new data stored in the 'new_data' variable
predictions = model.predict(Xt)

# 'predictions' will contain the model's output for the new data
# You can now use 'predictions' for further processing or analysis

thresholded_predictions = np.zeros_like(predictions)
thresholded_predictions[np.arange(len(predictions)), predictions.argmax(axis=1)] = 1

print(thresholded_predictions)

from sklearn.metrics import classification_report

# Create a classification report
report = classification_report(yt,thresholded_predictions)

# Print the classification report
print(report)

from sklearn.metrics import multilabel_confusion_matrix
# Create a classification report
report1 = multilabel_confusion_matrix(yt, thresholded_predictions)

# Print the classification report
print(report1)

# Calculate class-wise accuracy
class_accuracy = np.array([np.diag(conf_matrix) / np.sum(conf_matrix, axis=1) for conf_matrix in report1])

# Convert to percentage
class_accuracy_percentage = class_accuracy * 100

# Display class-wise accuracy
for i, acc in enumerate(class_accuracy_percentage):
    print(f"Class {i}: {acc[1]:.2f}%")  # Assuming the positive class is in the second row (index 1)

# Extract true positives (TP) from the confusion matrix
TP = report1[:, 1, 1]  # Assuming positive class is 1, modify accordingly

# Calculate accuracy
accuracy = TP.sum() / len(yt)
print(f"Accuracy: {accuracy:.2%}")

import os
import cv2  # Assuming you are using OpenCV for image loading
import numpy as np
from tensorflow.keras.models import load_model
import pandas as pd

# Define the preprocess_image function
def preprocess_image(image):
    # Resize the image to the required input shape of your model
    resized_image = cv2.resize(image,(224,224))  # Replace input_width and input_height with your model's input size

    # Normalize the image pixel values
    normalized_image = resized_image.astype('float32') / 255.0  # Assuming normalization to [0, 1]

    return normalized_image

# Load the model from the H5 file
model = load_model('VIT.plt')

# Directory containing test images
test_dir = '/content/drive/MyDrive/datset_test'

# List to store predictions for each image
all_predictions = []

# Iterate over the images in the directory
for filename in os.listdir(test_dir):
    # Load and preprocess the image
    image_path = os.path.join(test_dir, filename)
    image = cv2.imread(image_path)
    preprocessed_image = preprocess_image(image)  # Assuming you have a preprocess function

    # Reshape the preprocessed image as needed (if necessary)
    # preprocessed_image = np.expand_dims(preprocessed_image, axis=0)

    # Make predictions using the model
    predictions = model.predict(np.array([preprocessed_image]))

    # Interpret the predictions and store the result
    # For example, if your model outputs probabilities, you might set a threshold
    threshold = 0.5  # Example threshold for binary classification
    pcos_prediction = (predictions[0] > threshold).astype(int)
    all_predictions.append((filename, pcos_prediction))

# Convert the predictions to a pandas DataFrame
df = pd.DataFrame(all_predictions, columns=['Filename', 'Prediction'])

# Save the DataFrame to an Excel file
output_excel_file = 'predictions.xlsx'
df.to_excel(output_excel_file, index=False)

print(f"Predictions saved to '{output_excel_file}' ")

import pandas as pd
# Read the Excel file into a Pandas DataFrame
data = pd.read_excel("predictions.xlsx", header=None, names=['filename', 'values'])

# Access the column containing the values you want to count
values_column = data['values']
# Use the .value_counts() method to count the occurrences of each unique value
count_01 = values_column.value_counts().get('[0 1]', 0)
print("Count of [0 1]:", count_01)



model.summary()

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()



!pip install lime
import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries

# Create an explainer object
explainer = lime_image.LimeImageExplainer()

# Choose an example image from your test dataset
image = X_test[0]  # Adjust as needed

# Generate an explanation
explanation = explainer.explain_instance(image, model.predict, top_labels=5, num_samples=1000)

# Display the explanation
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries

# Load your images from a separate dataset
# Example: Assume images are stored in a directory 'separate_dataset'
# You need to adjust this based on how your data is stored
image_paths = ['/content/drive/MyDrive/datset_test/image10000.jpg', '/content/drive/MyDrive/datset_test/image10001.jpg','/content/drive/MyDrive/datset_test/image10002.jpg', "/content/drive/MyDrive/datset_test/image10003.jpg","/content/drive/MyDrive/datset_test/image10004.jpg"]  # Adjust as needed

# Prepare the images for input to the LIME explainer
images = []
for path in image_paths:
    img = tf.keras.preprocessing.image.load_img(path, target_size=(224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    images.append(img_array)

images = np.array(images)

# Create an explainer object
explainer = lime_image.LimeImageExplainer()

# Generate and visualize LIME explanations for each image
for image in images:
    # Generate an explanation
    explanation = explainer.explain_instance(image, model.predict, top_labels=5, num_samples=1000)

    # Display the explanation
    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
    plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))
    plt.show()

import tensorflow as tf
import numpy as np
from PIL import Image

# Load your pre-trained model
model_path = 'VIT.plt'  # Adjust the path to your model
model = tf.keras.models.load_model(model_path)

# Define a function to load and preprocess an image
def load_and_preprocess_image(image_path, image_width, image_height):
    image = Image.open(image_path)
    image = image.resize((image_width, image_height))
    image_array = np.array(image) / 255.0
    return image_array

# Load and preprocess your test images
test_image_paths = ['/content/drive/MyDrive/datset_test/image10001.jpg', '/content/drive/MyDrive/datset_test/image10021.jpg','/content/drive/MyDrive/datset_test/image10010.jpg',"/content/drive/MyDrive/datset_test/image10011.jpg","/content/drive/MyDrive/datset_test/image10012.jpg"]  # Adjust as needed
image_width = 224
image_height = 224
X_test = np.array([load_and_preprocess_image(path, image_width, image_height) for path in test_image_paths])

# Make predictions on the test images
predictions = model.predict(X_test)

# If you want to get the class labels for the predictions
predicted_classes = np.argmax(predictions, axis=1)

# If you want to get the probabilities for each class
predicted_probabilities = np.max(predictions, axis=1)

# Print the predicted classes and probabilities
for i, image_path in enumerate(test_image_paths):
    print(f"Image: {image_path}, Predicted Class: {predicted_classes[i]}, Probability: {predicted_probabilities[i]}")

import tensorflow as tf
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# Load your pre-trained model
model_path = 'VIT.plt'  # Adjust the path to your model
model = tf.keras.models.load_model(model_path)

# Define a function to load and preprocess an image
def load_and_preprocess_image(image_path, image_width, image_height):
    image = Image.open(image_path)
    image = image.resize((image_width, image_height))
    image_array = np.array(image) / 255.0
    return image_array

# Define the test image paths
test_image_paths = ['/content/drive/MyDrive/datset_test/image10022.jpg', '/content/drive/MyDrive/datset_test/image10037.jpg','/content/drive/MyDrive/datset_test/image10063.jpg',"/content/drive/MyDrive/datset_test/image10055.jpg","/content/drive/MyDrive/datset_test/image10037.jpg"]  # Adjust as needed

# Load and preprocess the test images
image_width = 224
image_height = 224
X_test = np.array([load_and_preprocess_image(path, image_width, image_height) for path in test_image_paths])

# Make predictions on the test images
predictions = model.predict(X_test)

# If you want to get the class labels for the predictions
predicted_classes = np.argmax(predictions, axis=1)

# If you want to get the probabilities for each class
predicted_probabilities = np.max(predictions, axis=1)

# Display the images with their predicted classes and probabilities
plt.figure(figsize=(15, 10))
for i, (image, predicted_class, probability) in enumerate(zip(X_test, predicted_classes, predicted_probabilities), 1):
    plt.subplot(1, len(test_image_paths), i)
    plt.imshow(image)
    plt.title(f'Class: {predicted_class},')
    plt.axis('off')

plt.show()











